2025-1 고급 백엔드 스터디 week12
================================
* # 6장 B-트리의 변형
    * ## Bw-트리
        * `쓰기 증폭(write amplification)`은 트리의 인플레이스 업데이트 구현에서 가장 중요한 문제다.
            * 연속된 B-트리 페이지 수정으로 인해 디스크에 저장된 페이지 원본을 모든 요청마다 업데이트하는 상황이 발생할 수 있기 때문이다.
        
        * 업데이트를 위한 공간을 미리 확보하면서 `메모리 증폭(space amplification)`이 발생할 수 있다.
            * 요청된 데이터를 담고 있는 유용한 바이트를 전송하려면 매번 빈 바이트와 해당 페이지의 나머지 부분을 같이 전송해야 한다.
        
        * 마지막으로 해결하기 어려운 `동시성 문제`와 `래치 사용의 복잡성` 문제가 있다.

        * 위의 세 가지 문제를 한번에 해결하려면, 추가 전용 스토리지를 사용해 여러 노드에 대한 업데이트를 일괄 적용하고 노드를 서로 연결해 체인을 형성하는 방법이 있다.
            * 한 번의 CAS 연산으로 노드 사이를 연결하는 포인터를 생성할 수 있는 인메모리 자료 구조를 사용하면 잠금이 필요 없는 트리를 만들 수 있다. 이런 방식의 트리를 `Buzzword-트리(Bw-트리)`라고 한다.
        
        * ### 체인 업데이트
            * Bw-트리는 변경 사항과 원본 노드를 따로 저장한다.
                * 변경 사항(델타 노드)는 체인을 형성한다.
                    * 가장 최신 수정본부터 순서대로 정렬하고 원본 노드를 가장 마지막에 저장한 링크트 리스트 형태의 체인이다.
                    
                    * 각 업데이트 내용을 따로 저장하면 디스크에 저장된 원본 노드를 수정하지 않아도 된다.

                    * 델타 노드는 삽입과 업데이트, 삭제 작업을 모두 포함한다.
                
            * 원본과 델타 노드의 크기는 페이지 크기와 일치하지 않을 가능성이 높으므로 연속된 공간에 저장하는 것이 합리적이다.
                * 두 노드 모두 업데이트되지 않으므로 추가 공간을 미리 할당하지 않아도 된다.
                * 모든 업데이트는 단순히 링크드 리스트에 노드를 추가하는 방식이다.
            
            * 노드를 논리적 개체로 사용하는 접근 방식을 이용한다.
                * 공간을 미리 할당하거나, 노드의 크기를 고정하고 연속된 메모리 세그먼트에 저장하지 않아도 된다.
                * 이 방식은 읽기 작업 시 모든 델타 노드를 순회해 원본 노드를 최신 상태로 동기화해야 한다는 단점이 있다.
                * 이 방식은 변경 사항을 메인 자료 구조와 별도로 저장하고 읽기 시 반영하는 LA-트리(지연 적응형 트리)와 유사하다.
        
        * ### CAS 연산으로 동시성 문제 해결
            * 노드의 앞에 데이터를 추가할 수 있는 디스크 기반 트리는 유지 비용이 매우 높다.
                * 부모 노드가 새로운 델타 노드를 가리키도록 주기적으로 업데이트해야 하기 때문이다.
            
            * Bw-트리는 원본과 델타 노드 외에 논리적 식별자와 디스크에서의 위치를 매핑하는 인메모리 매핑 테이블을 저장한다.
                * 매핑 테이블을 사용하면 쓰기 작업 시 배타적 잠금을 획득하는 대신 매핑 테이블의 물리적 오프셋을 `CAS(Compare-and-swap)` 연산으로 변경할 수 있기 때문에 래치가 필요 없다.
            
            * Bw-트리의 노드 업데이트 알고리즘 단계
                1. 루트 노드에서 리프 노드까지 순회하면서 대상 논리적 리프 노드를 찾는다. 매핑 테이블에는 원본 노드 또는 업데이트 체인에서 가장 최신 델타 노드를 가리키는 가상 링크를 저장한다.
                2. 1단계에서 찾은 원본 노드(또는 최신 델타 노드)를 가리키는 새로운 델타 노드를 생성한다.
                3. 2단계에서 생성한 델타 노드를 가리키는 포인터를 매핑 테이블에 업데이트한다.

            * 앞의 작업 3단계에서 CAS를 사용한다.
                * CAS는 원자적인 연산이므로 포인터 업데이트와 동시에 요청된 모든 읽기 작업은 리더와 라이터를 블록하지 않고 업데이트 작업 전 또는 후에 실행한다.
                * 업데이트 작업 전에 실행되는 읽기 작업은 기존 포인터를 참조하기 때문에 아직 추가되지 않은 새로운 델타 노드에 대해서 알 수 없다.
                * 업데이트 작업 후에 실행되는 읽기 작업은 새로운 포인터를 참조해 최신 상태를 볼 수 있다.
        
        * ### 구조 변경 작업
            * Bw-트리는 논리적으로 B-트리와 구조가 같다. 따라서 노드는 너무 크거나(오버플로우 발생) 거의 비어 있는(언더플로우 상태) 상태일 수 없으며 분할 및 병합 등의 `구조 변경 작업(SMO, Structure Modification Operation)`이 필요하다.

            * 분할 SMO는 분할 대상 노드의 원본 노드에 델타를 반영해 논리적 상태를 최신 상태로 업데이트하고 분할 지점의 오른쪽에 새로운 페이지를 추가한다.
                * 분할 SMO 절차
                    1. 분할 : 리더가 분할이 진행 중이라는 사실을 알 수 있도록 특수한 `분할 델타(split delta)` 노드를 분할 노드의 끝에 추가한다. 분할 델타 노드는 분할 노드의 레코드를 무효화하기 위한 중간 지점의 구분 키와 새로운 형제 노드를 가리키는 링크로 구성된다.
                    2. 부모 노드 업데이트 : 새로운 노드는 분할 델타 노드 포인터를 통해 접근할 수 있지만 아직 참조하는 부모 노드가 없다. 리더는 분할 노드의 형제 포인터를 통해 접근할 수밖에 없다. 리더가 분할 노드를 통하지 않고 바로 새로운 노드에 접근할 수 있도록 노들르 가리키는 포인터를 부모 노드에 추가하면 분할 작업이 완료된다.
                
                * Bw-트리는 래치를 사용하지 않기 때문에 어떤 스레드도 불완전한 SMO의 결과에 접근할 수 있다.

                * 다음 스레드가 형제 포인터가 아닌 새로운 부모 포인터를 통해 새로운 노드에 접근할 수 있도록 스레드는 진행 전에 미완료된 다중 단계의 SMO를 완료해야 한다.
            
            * 병합 SMO
                * 병합 SMO 절차
                    1. 형제 노드 제거 : 병합 SMO의 시작과 삭제 대상 노드를 의미하는 특수 `삭제 델타(remove delta)` 노드를 오른쪽 형제 노드에 추가한다.
                    2. 병합 : 왼쪽 형제 노드에 오른쪽 형제 노드를 가리키는 `병합 델타(merge delta)`를 추가해 오른쪽 형제 노드를 왼쪽 형제 노드의 논리적 노드로 만든다.
                    3. 부모 노드 업데이트 : 왼쪽 형제 노드에서 오른쪽 형제 노드의 요소에 접근할 수 있다. 부모 노드에서 오른쪽 자식 노드를 가리키는 포인터를 삭제하면 병합 작업이 완료된다.
            
            * SMO가 동시에 같은 노드를 분할 또는 병합하는 것을 방지하기 위해 부모 노드에 `중지 델타(abort delta)`를 추가해야 한다.
                * 중지 델타 노드는 쓰기 잠금과 유사하여, 동시에 한 개의 스레드만이 노드에 대한 쓰기 권한을 가질 수 있고 해당 델타 노드에 새로운 노드를 추가하는 모든 다른 스레드는 중단된다.
                * SMO가 완료되면 부모에서 중지 델타 노드를 제거한다.
            
            * 루트 노드 분할 시 Bw-트리의 높이가 증가한다. 루트 노드가 일정 크기 이상으로 커지면 새로운 루트 노드를 생성하고 기존 루트 노드와 새로운 노드가 자식 노드가 된다.

        * ### 노드 통합과 가비지 컬렉션
            * 아무 조치를 취하지 않으면 델타 체인은 매우 길어질 수 있다. 델타 체인이 길어질수록 읽기 작업 비용이 증가하므로 길이를 적당히 유지해야 한다.
                * 체인의 길이가 설정해둔 상한에 도달하면 원본 노드와 델타 노드를 합쳐서 새로운 원본 노드로 통합한다.
                * 통합된 노드는 디스크의 새로운 위치에 저장하고 매핑 테이블의 노드 포인터가 새로운 노드를 가리키도록 업데이트한다.
            
            * 노드가 통합되면 기존 내용(원본 노드와 모든 델타 노드)은 더 이상 매핑 테이블을 통해 접근할 수 없다.
                * 한편 다른 진행 중인 작업에서 해당 부분을 참조하고 있을 수 있기 때문에 바로 메모리를 해제하지 않는다.
            
            * 특정 노드에 대한 접근이 허용되는 스레드와 허용되지 않는 스레드를 구분하기 위해 Bw-트리는 `에포크 기반의 교정 기법(epoch-based reclamation)`을 사용한다.
                * 특정 시점에 일부 노드와 델타가 통합으로 인해 매핑 테이블에서 삭제돼도 기존 노드는 해당 시점 또는 이전에 시작된 리더가 작업을 완료할 때까지 유지해야 한다. 이후에 시작한 리더는 해당 노드에 절대 접근할 수 없기 때문에 작업이 완료되면 안전하게 가비지 컬렉션을 통해 정리한다.
        
    
    * ## 캐시 비인지형 B-트리
        * 블록 크기와 노드 크기, 캐시 라인 얼라인먼트를 포함한 여러 다른 설정 가능한 파라미터가 B-트리의 성능에 영향을 미친다.
            * `캐시 비인지형(cache-oblivious) 자료 구조`는 메모리 계층 구조와 파라미터 조정 여부와 상관없이 점근적으로 최적의 성능을 보장한다.
                * 알고리즘이 캐시 라인과 파일시스템 블록, 디스크 페이지의 크기와 무관하다.
                * 캐시 비인지형 자료 구조는 설정이 다른 여러 서버에서 추가 설정 없이 잘 작동하도록 설계되었다.
        
        * 2-레벨 계층 구조는 페이지 캐시와 디스크로 구성된다.
            * 두 개의 레벨로 구성된다는 것은 각 레벨과 관련된 세부 사항을 처리하는 레벨별 코드 모듈이 두 개만 있으면 된다는 것을 의미하며, 알고리즘 설계가 비교적 수월해진다.

        * `캐시 인지형(cache-aware) 방식`에서 디스크는 여러 블록으로 나뉘고 데이터는 디스크와 캐시 사이에 블록 단위로 전송할 때, 알고리즘이 블록 안에 한 개의 레코드만을 요청해도 블록 전체를 읽는다.

        * 캐시 비인지형 알고리즘은 멀티 레벨 계층 구조의 이점을 제공하면서 자료 구조를 2-레벨 메모리 계층 구조의 관점에서 바라볼 수 있다.
            * 이 방식은 플랫폼에 종속적인 파라미터가 필요 없고 레벨 사이의 전송 횟수를 상수 범위 내로 보장한다.
            * 만약 자료 구조가 어느 두 레벨의 메모리 계층에서 최적의 성능를 내도록 최적화됐다면 인접하는 다른 두 레벨에서도 최적으로 작동한다.
        
        * ### 반 엠데 보아스 레이아웃
            * 캐시 비인지형 B-트리는 정적 B-트리와 패킹된 배열로 구성된다.
                * 정적 B-트리는 `반 엠데 보아스(vEB, van Emde Boas) 레이아웃`을 기반으로 생성한다.
                * 트리의 에지를 잘라 분할하고 재귀적으로 각 서브트리를 분할하면 sqr(N) 크기의 여러 서브트리가 생긴다. 이 레이아웃의 핵심은 모든 재귀적 트리는 연속된 메모리 블록에 저장된다는 점이다.
            
            * 자료 구조를 동적으로 제어하기 위해(삽입과 업데잍, 삭제 허용 등) 캐시 비인지형 트리에서는 `패킹된 배열 자료 구조`를 사용한다.
                * 연속된 메모리 세그먼트를 이용해 원소들을 저장하지만, 나중에 삽입될 원소들을 위한 갭을 마련해둔다.
                    * 갭의 간격은 밀도 기준값에 따라 설정한다.
                    * 이 방식은 더 적은 재배치 횟수로 트리에 요소를 삽입할 수 있다.
                    * 새로운 요소가 들어갈 갭이 없을 경우 다른 요소를 재배치해야 한다.
                    * 패킹된 배열의 밀집도가 너무 높거나 너무 낮은 경우 크기를 줄이거나 확장하기 위해 배열을 재구성해야 한다.
            
            * 정적 트리는 최하위 레벨의 패킹된 배열의 인덱스로 사용한다.
                * 재배치된 요소가 최하위 레벨의 해당 요소를 가리키도록 업데이트해야 한다.